# Discrimination: Presentation Notes

AI is convenient, faster and provides more extensive research data than humans can muster in seconds (Chen, 2022). We have to be careful with this because AI can make unjust outcomes that treat marginalized groups and individuals poorly. 

Due to their training data reflecting historical biases, AI can make ethical mistakes in hiring, financial lending and healthcare environments (Shubair, 2025).

A few ways to remedy this problem is by updating the AI with unbiased frameworks, improving transparency and collecting user data on experiences with AI recruitment and discrimination (Chen, 2023).

## Presentation Slide Layout

**Problems**
- AI is convenient and fast!
- Easy to make big mistakes such as discrimination
- Ethical mistakes can occur in hiring, financial lending and healthcare

**Solutions**
- Unbiased frameworks
- Transparency
- Collecting user data

## Reference
Chen, Z. (2022, Feb 24). Artificial intelligence-virtual trainer: innovative didactics aimed at personalized training needs. J Knowl Econ. https://link.springer.com/article/10.1007/s13132-022-00985-0

Chen, Z. (2023, Sept 13). Ethics and discrimination in artificial intelligence-enabled recruitment practices. Nature. https://www.nature.com/articles/s41599-023-02079-x

Shubair, I. (2025, May 8). Researcher tackles discrimination and inherent bias in AI systems. Mcmaster. https://news.mcmaster.ca/maryam-ghasemaghaei-canada-research-chair-tackles-discrimination-inherent-bias-in-ai-systems/
